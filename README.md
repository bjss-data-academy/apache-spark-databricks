# Working with Apache Spark in Databricks

_Databricks_ and _Apache Spark_ provide indeustry-standard tools to work with big data analytics.

Together, they provide tools to:

- Organise data at petabyte scale
- Analyse data
- Control data access
- Manage high-performance computing clusters
- Work with real-time streaming data
- Apply machine learning to data
- Work with Python, SQL, R, Scala and Java in any combination
  
This course covers using Apache Spark tools inside Databricks. 

The general principles are common to all analytics solutions. Examples will be specific to Databircks/Spark.

# Next
Let's start with some basics - how to enter code in Databricks notebooks:
[Using Notebooks](/notebooks.md)

[Back to Contents](/contents.md)
