# Spark Execution Architecture

To get the best performance from Spark, we need to take advantage of how it operates on large data sets.

Spark is designed to work with large volumes of data in a cloud-native environment. It will manage concurrent processing of data in a cluster of servers, and collection of results into a single output.

Let's review all the various pieces that make up a Spark cluster:

![Spark execution architecture](/images/executors.png)

TODO explain pieces
