# Spark DataFrame

- overview
- columnar data optimised
- why that matters

- universal chunk of data
- columns and data types
- supported data types

input and output
- read and write many formats
- csv
- sql - Spark SQL is a thing see link
- json
- parquet - columnar datab adds acid, versioning


working with data frames
- load file
- rename column
- add new column
- aggregation
- business purpose olap oltp - see overall results
- write file
- parquet by default ??
- code examples throughout
  

# Next
[Transforming Data](/transforming-data.md)

[Back to Contents](/contents.md)
