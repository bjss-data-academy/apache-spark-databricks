# Spark DataFrame

- overview
- columnar data optimised
- why that matters

- universal chunk of data
- read and write many formats
- csv
- sql - Spark SQL is a thing see link
- json
- parquet

working with data frames
- load file
- rename column
- add new column
- aggregation
- business purpose olap oltp - see overall results
- write file
- - parquet by default IIRC explain benefits
- code example
  

# Next
[Transforming Data](/transforming-data.md)

[Back to Contents](/contents.md)
